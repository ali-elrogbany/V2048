{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing helpers\n",
    "mp_hands = mp.solutions.hands  # Mediapipe Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHandPoints(videoURL, label):\n",
    "    cap = cv2.VideoCapture(videoURL)\n",
    "\n",
    "    # Initiate hands model\n",
    "    with mp_hands.Hands(max_num_hands = 1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        points = []\n",
    "        wrist = []\n",
    "        left_thumb_tip = []\n",
    "        left_thumb_mcp = []\n",
    "        left_index_tip = []\n",
    "        left_index_mcp = []\n",
    "        left_middle_tip = []\n",
    "        left_middle_mcp = []\n",
    "        left_ring_tip = []\n",
    "        left_ring_mcp = []\n",
    "        left_pinky_tip = []\n",
    "        left_pinky_mcp = []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret==True:\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                # Make Detections\n",
    "                results = hands.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Draw landmarks on frame\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                            mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                        )\n",
    "\n",
    "                    if results.multi_hand_landmarks:\n",
    "                        wrist.append(Point(results.multi_hand_landmarks[0].landmark[0].x, results.multi_hand_landmarks[0].landmark[0].y, 1))\n",
    "\n",
    "                        left_thumb_tip.append(Point(results.multi_hand_landmarks[0].landmark[4].x, results.multi_hand_landmarks[0].landmark[4].y, 2))\n",
    "                        left_thumb_mcp.append(Point(results.multi_hand_landmarks[0].landmark[2].x, results.multi_hand_landmarks[0].landmark[2].y, 3))\n",
    "\n",
    "                        left_index_tip.append(Point(results.multi_hand_landmarks[0].landmark[8].x, results.multi_hand_landmarks[0].landmark[8].y, 4))\n",
    "                        left_index_mcp.append(Point(results.multi_hand_landmarks[0].landmark[5].x, results.multi_hand_landmarks[0].landmark[5].y, 5))\n",
    "\n",
    "                        left_middle_tip.append(Point(results.multi_hand_landmarks[0].landmark[12].x, results.multi_hand_landmarks[0].landmark[12].y, 6))\n",
    "                        left_middle_mcp.append(Point(results.multi_hand_landmarks[0].landmark[9].x, results.multi_hand_landmarks[0].landmark[9].y, 7))\n",
    "\n",
    "                        left_ring_tip.append(Point(results.multi_hand_landmarks[0].landmark[16].x, results.multi_hand_landmarks[0].landmark[16].y, 8))\n",
    "                        left_ring_mcp.append(Point(results.multi_hand_landmarks[0].landmark[13].x, results.multi_hand_landmarks[0].landmark[13].y, 9))\n",
    "\n",
    "                        left_pinky_tip.append(Point(results.multi_hand_landmarks[0].landmark[20].x, results.multi_hand_landmarks[0].landmark[20].y, 10))\n",
    "                        left_pinky_mcp.append(Point(results.multi_hand_landmarks[0].landmark[17].x, results.multi_hand_landmarks[0].landmark[17].y, 11))\n",
    "\n",
    "                cv2.imshow(label, image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Combine all points for $1 recognizer\n",
    "        points = wrist + left_thumb_tip + left_thumb_mcp + left_index_tip + left_index_mcp + left_middle_tip + left_middle_mcp + left_ring_tip + left_ring_mcp + left_pinky_tip + left_pinky_mcp\n",
    "        print(label)\n",
    "        return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down\n",
      "Down\n",
      "Down\n"
     ]
    }
   ],
   "source": [
    "vid = \"vids/down/d_ali.mp4\"\n",
    "points = getHandPoints(vid,\"Down\") \n",
    "tmpl_2 = Template('Down', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/down/d_bakar.mp4\"\n",
    "# points = getHandPoints(vid,\"Down\") \n",
    "# tmpl_2 = Template('Down', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/down/d_fouad.mp4\"\n",
    "# points = getHandPoints(vid,\"Down\") \n",
    "# tmpl_2 = Template('Down', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/down/d_kamal.mp4\"\n",
    "# points = getHandPoints(vid,\"Down\") \n",
    "# tmpl_2 = Template('Down', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "vid = \"vids/down/d_marwan.mp4\"\n",
    "points = getHandPoints(vid,\"Down\") \n",
    "tmpl_2 = Template('Down', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "vid = \"vids/down/d_kenzy.mp4\"\n",
    "points = getHandPoints(vid,\"Down\") \n",
    "tmpl_2 = Template('Down', points)\n",
    "templates.append(tmpl_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left\n",
      "Left\n",
      "Left\n"
     ]
    }
   ],
   "source": [
    "vid = \"vids/left/l_ali.mp4\"\n",
    "points = getHandPoints(vid,\"Left\") \n",
    "tmpl_2 = Template('Left', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/left/l_bakar.mp4\"\n",
    "# points = getHandPoints(vid,\"Left\") \n",
    "# tmpl_2 = Template('Left', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/left/l_fouad.mp4\"\n",
    "# points = getHandPoints(vid,\"Left\") \n",
    "# tmpl_2 = Template('Left', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/left/l_kamal.mp4\"\n",
    "# points = getHandPoints(vid,\"Left\") \n",
    "# tmpl_2 = Template('Left', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "vid = \"vids/left/l_marwan.mp4\"\n",
    "points = getHandPoints(vid,\"Left\") \n",
    "tmpl_2 = Template('Left', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "vid = \"vids/left/l_kenzy.mp4\"\n",
    "points = getHandPoints(vid,\"Left\") \n",
    "tmpl_2 = Template('Left', points)\n",
    "templates.append(tmpl_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right\n",
      "Right\n",
      "Right\n"
     ]
    }
   ],
   "source": [
    "vid = \"vids/right/r_ali.mp4\"\n",
    "points = getHandPoints(vid,\"Right\") \n",
    "tmpl_2 = Template('Right', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/right/r_bakar.mp4\"\n",
    "# points = getHandPoints(vid,\"Right\") \n",
    "# tmpl_2 = Template('Right', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/right/r_fouad.mp4\"\n",
    "# points = getHandPoints(vid,\"Right\") \n",
    "# tmpl_2 = Template('Right', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/right/r_kamal.mp4\"\n",
    "# points = getHandPoints(vid,\"Right\") \n",
    "# tmpl_2 = Template('Right', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "vid = \"vids/right/r_marwan.mp4\"\n",
    "points = getHandPoints(vid,\"Right\") \n",
    "tmpl_2 = Template('Right', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "vid = \"vids/right/r_kenzy.mp4\"\n",
    "points = getHandPoints(vid,\"Right\") \n",
    "tmpl_2 = Template('Right', points)\n",
    "templates.append(tmpl_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n",
      "Up\n",
      "Up\n"
     ]
    }
   ],
   "source": [
    "vid = \"vids/up/u_ali.mp4\"\n",
    "points = getHandPoints(vid,\"Up\") \n",
    "tmpl_2 = Template('Up', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/up/u_bakar.mp4\"\n",
    "# points = getHandPoints(vid,\"Up\") \n",
    "# tmpl_2 = Template('Up', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/up/u_fouad.mp4\"\n",
    "# points = getHandPoints(vid,\"Up\") \n",
    "# tmpl_2 = Template('Up', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "# vid = \"vids/up/u_kamal.mp4\"\n",
    "# points = getHandPoints(vid,\"Up\") \n",
    "# tmpl_2 = Template('Up', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "vid = \"vids/up/u_marwan.mp4\"\n",
    "points = getHandPoints(vid,\"Up\") \n",
    "tmpl_2 = Template('Up', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "vid = \"vids/up/u_kenzy.mp4\"\n",
    "points = getHandPoints(vid,\"Up\") \n",
    "tmpl_2 = Template('Up', points)\n",
    "templates.append(tmpl_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleOutcomes = [\"Left\", \"Right\", \"Up\", \"Down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a connection...\n",
      "Device connected: ('127.0.0.1', 62720)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "soc = socket.socket()\n",
    "hostname = \"localhost\"\n",
    "port = 65436\n",
    "soc.bind((hostname, port))\n",
    "soc.listen(5)\n",
    "\n",
    "print(\"Waiting for a connection...\")\n",
    "conn, addr = soc.accept()\n",
    "print(\"Device connected: \" + str(addr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_hand_pose_detection(videoURL=0):\n",
    "    recognizer = Recognizer(templates)\n",
    "    cap = cv2.VideoCapture(videoURL)\n",
    "\n",
    "    # Initiate hands model\n",
    "    with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7) as hands:\n",
    "        wrist = []\n",
    "        left_thumb_tip = []\n",
    "        left_thumb_mcp = []\n",
    "        left_index_tip = []\n",
    "        left_index_mcp = []\n",
    "        left_middle_tip = []\n",
    "        left_middle_mcp = []\n",
    "        left_ring_tip = []\n",
    "        left_ring_mcp = []\n",
    "        left_pinky_tip = []\n",
    "        left_pinky_mcp = []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret:\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False \n",
    "\n",
    "                # Detect hands\n",
    "                results = hands.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                gesture_name = \"No Hands Detected\"\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        # Draw landmarks\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                            mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                        )\n",
    "\n",
    "                        if results.multi_hand_landmarks:\n",
    "                            wrist.append(Point(results.multi_hand_landmarks[0].landmark[0].x, results.multi_hand_landmarks[0].landmark[0].y, 1))\n",
    "\n",
    "                            left_thumb_tip.append(Point(results.multi_hand_landmarks[0].landmark[4].x, results.multi_hand_landmarks[0].landmark[4].y, 2))\n",
    "                            left_thumb_mcp.append(Point(results.multi_hand_landmarks[0].landmark[2].x, results.multi_hand_landmarks[0].landmark[2].y, 3))\n",
    "\n",
    "                            left_index_tip.append(Point(results.multi_hand_landmarks[0].landmark[8].x, results.multi_hand_landmarks[0].landmark[8].y, 4))\n",
    "                            left_index_mcp.append(Point(results.multi_hand_landmarks[0].landmark[5].x, results.multi_hand_landmarks[0].landmark[5].y, 5))\n",
    "\n",
    "                            left_middle_tip.append(Point(results.multi_hand_landmarks[0].landmark[12].x, results.multi_hand_landmarks[0].landmark[12].y, 6))\n",
    "                            left_middle_mcp.append(Point(results.multi_hand_landmarks[0].landmark[9].x, results.multi_hand_landmarks[0].landmark[9].y, 7))\n",
    "\n",
    "                            left_ring_tip.append(Point(results.multi_hand_landmarks[0].landmark[16].x, results.multi_hand_landmarks[0].landmark[16].y, 8))\n",
    "                            left_ring_mcp.append(Point(results.multi_hand_landmarks[0].landmark[13].x, results.multi_hand_landmarks[0].landmark[13].y, 9))\n",
    "\n",
    "                            left_pinky_tip.append(Point(results.multi_hand_landmarks[0].landmark[20].x, results.multi_hand_landmarks[0].landmark[20].y, 10))\n",
    "                            left_pinky_mcp.append(Point(results.multi_hand_landmarks[0].landmark[17].x, results.multi_hand_landmarks[0].landmark[17].y, 11))\n",
    "\n",
    "                            if len(wrist) > 20:\n",
    "                                wrist.pop(0)\n",
    "\n",
    "                                left_thumb_tip.pop(0)\n",
    "                                left_thumb_mcp.pop(0)\n",
    "\n",
    "                                left_index_tip.pop(0)\n",
    "                                left_index_mcp.pop(0)\n",
    "\n",
    "                                left_middle_tip.pop(0)\n",
    "                                left_middle_mcp.pop(0)\n",
    "\n",
    "                                left_ring_tip.pop(0)\n",
    "                                left_ring_mcp.pop(0)\n",
    "\n",
    "                                left_pinky_tip.pop(0)\n",
    "                                left_pinky_mcp.pop(0)\n",
    "\n",
    "                                points = wrist + left_thumb_tip + left_thumb_mcp + left_index_tip + left_index_mcp + left_middle_tip + left_middle_mcp + left_ring_tip + left_ring_mcp + left_pinky_tip + left_pinky_mcp\n",
    "\n",
    "                                result = recognizer.recognize(points)\n",
    "                                gesture_name = result[0]\n",
    "\n",
    "\n",
    "\n",
    "                # Display gesture name on frame\n",
    "                cv2.putText(image, f'Gesture: {gesture_name}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                cv2.imshow(\"Real-Time Hand Gesture Detection\", image)\n",
    "\n",
    "                try:\n",
    "                    if gesture_name.strip():\n",
    "                        if gesture_name in possibleOutcomes:\n",
    "                            msg = (gesture_name + \"\\n\").encode(\"ASCII\")\n",
    "                            try:\n",
    "                                conn.send(msg)\n",
    "                            except BrokenPipeError:\n",
    "                                print(\"Client disconnected. Stopping server.\")\n",
    "                                break\n",
    "                    else:\n",
    "                        print(\"Please enter a valid direction.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                conn.close()\n",
    "                soc.close()\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "real_time_hand_pose_detection(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
